{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-summary\n!pip install line_profiler","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:26.271274Z","iopub.execute_input":"2021-11-20T11:16:26.271644Z","iopub.status.idle":"2021-11-20T11:16:43.120741Z","shell.execute_reply.started":"2021-11-20T11:16:26.271565Z","shell.execute_reply":"2021-11-20T11:16:43.119897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchsummary import summary\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-20T11:16:43.122439Z","iopub.execute_input":"2021-11-20T11:16:43.122824Z","iopub.status.idle":"2021-11-20T11:16:44.442309Z","shell.execute_reply.started":"2021-11-20T11:16:43.122777Z","shell.execute_reply":"2021-11-20T11:16:44.441591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_len = 1014\nbatch_size = 64\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:44.443824Z","iopub.execute_input":"2021-11-20T11:16:44.444077Z","iopub.status.idle":"2021-11-20T11:16:44.4975Z","shell.execute_reply.started":"2021-11-20T11:16:44.444041Z","shell.execute_reply":"2021-11-20T11:16:44.496601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:’’’/\\|_@#$%ˆ&*˜‘+-=<>()[]{}\"\nchar_map = {char:idx for idx, char in enumerate(alphabet)}\n\ndef generate_embedding_matrix(size=len(alphabet)):\n    return torch.vstack([torch.eye(size), torch.zeros(size)])","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:44.499684Z","iopub.execute_input":"2021-11-20T11:16:44.500189Z","iopub.status.idle":"2021-11-20T11:16:44.508407Z","shell.execute_reply.started":"2021-11-20T11:16:44.500152Z","shell.execute_reply":"2021-11-20T11:16:44.507676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CharCNN(nn.Module):\n    def __init__(self, input_dim, enc_dim, output_dim, net_type=\"small\"):\n        super().__init__()\n        \n        self.input_dim = input_dim\n        self.enc_dim = enc_dim\n        \n        if net_type == \"small\":\n            self.latent_size = 1024\n            self.cnn_features = 256\n        else:\n            self.latent_size = 2048\n            self.cnn_features = 1024\n        \n        self.embed = nn.Embedding.from_pretrained(generate_embedding_matrix(enc_dim), freeze=True)\n        self.cnn, w_size = self.generate_cnn([\n            # Kernel Size, Pooling Kernel Size\n            [7, 3], # L1\n            [7, 3], # L2\n            [3, 0], # L3\n            [3, 0], # L4\n            [3, 0], # L5\n            [3, 3]  # L6\n        ])\n        self.fc = nn.Sequential(\n            nn.Linear(w_size * self.cnn_features, self.latent_size),\n            nn.Linear(self.latent_size, self.latent_size),\n            nn.Linear(self.latent_size, output_dim)\n        )\n    \n    def generate_cnn(self, layer_params):\n        cnn_layers = []\n        feature_w = self.input_dim\n        for idx, (kernel_size, pool_size) in enumerate(layer_params):\n            inp_size = self.enc_dim if idx == 0 else self.cnn_features\n            feature_w = feature_w - kernel_size + 1\n            cnn_layers.append(nn.Conv1d(inp_size, self.cnn_features, kernel_size))\n            if pool_size != 0:\n                feature_w = feature_w // pool_size\n                cnn_layers.append(nn.MaxPool1d(pool_size))\n        return nn.Sequential(*cnn_layers), feature_w\n    \n    def forward(self, x):\n        encoded_x = torch.stack(list(self.embed(item) for item in x)).permute(0, 2, 1)\n        cnn_out = self.cnn(encoded_x)\n        fc_in = torch.flatten(cnn_out, start_dim=1)\n        fc_out = self.fc(fc_in)\n        return torch.sigmoid(fc_out)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:28:49.147002Z","iopub.execute_input":"2021-11-20T11:28:49.147825Z","iopub.status.idle":"2021-11-20T11:28:49.160549Z","shell.execute_reply.started":"2021-11-20T11:28:49.147786Z","shell.execute_reply":"2021-11-20T11:28:49.159877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class YelpPolarity(Dataset):\n    def __init__(self, csv_path):\n        self.data_frame = pd.read_csv(csv_path)\n    \n    def __len__(self):\n        return len(self.data_frame)\n    \n    def __getitem__(self, idx):\n        data_instance = self.data_frame.iloc[idx]\n        inp_string = data_instance[1]\n        inp_string = inp_string[:min(char_len, len(inp_string))]\n        if \"A\" not in alphabet: inp_string = inp_string.lower()\n            \n        X_lis = [len(alphabet)] * char_len\n        X_lis[:len(inp_string)] = [char_map.get(char, len(alphabet)) for char in inp_string]\n        \n        X = torch.LongTensor(X_lis)\n        y = torch.FloatTensor([data_instance[0]])\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:53.17801Z","iopub.execute_input":"2021-11-20T11:16:53.17842Z","iopub.status.idle":"2021-11-20T11:16:53.186977Z","shell.execute_reply.started":"2021-11-20T11:16:53.17838Z","shell.execute_reply":"2021-11-20T11:16:53.186159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dset = YelpPolarity('../input/yelp-review-polarity/yelp_review_polarity_csv/train.csv')\ntrain_loader = torch.utils.data.DataLoader(train_dset, batch_size=batch_size, shuffle=True, num_workers=2)\n\ntest_dset = YelpPolarity('../input/yelp-review-polarity/yelp_review_polarity_csv/test.csv')\ntest_loader = torch.utils.data.DataLoader(test_dset, batch_size=batch_size, shuffle=False, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:16:53.189772Z","iopub.execute_input":"2021-11-20T11:16:53.189999Z","iopub.status.idle":"2021-11-20T11:17:00.19406Z","shell.execute_reply.started":"2021-11-20T11:16:53.18994Z","shell.execute_reply":"2021-11-20T11:17:00.193278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = CharCNN(char_len, 70, 2).to(device)\nsummary(net, torch.zeros((2, char_len)).long())\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:34:20.516027Z","iopub.execute_input":"2021-11-20T11:34:20.516505Z","iopub.status.idle":"2021-11-20T11:34:20.636398Z","shell.execute_reply.started":"2021-11-20T11:34:20.516467Z","shell.execute_reply":"2021-11-20T11:34:20.635444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in tqdm(range(2)):\n    running_loss = 0.0\n    for i, data in enumerate(tqdm(train_loader, leave=False), 0):\n        indices, labels = data\n        \n        indices = indices.to(device)\n        labels = (labels.long() - 1).to(device)\n        \n        optimizer.zero_grad()\n        outputs = net(indices)\n        \n        loss = criterion(outputs, labels.flatten())\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        if i % 100 == 99:\n            print('[%d, %5d] loss: %.3f \\t %.3f' % (epoch + 1, i + 1, running_loss / 2000, loss.item()))\n            running_loss = 0.0\n\nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2021-11-20T11:37:17.111758Z","iopub.execute_input":"2021-11-20T11:37:17.112373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}